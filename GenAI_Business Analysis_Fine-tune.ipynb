{"cells":[{"cell_type":"markdown","metadata":{"id":"1Rp80dTGpsDD"},"source":["### Set up the project environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx4wV2MIUJ8A"},"outputs":[],"source":["!pip install openai==1.7.2 python-dotenv"]},{"cell_type":"markdown","metadata":{"id":"qypdUNULptjB"},"source":["Importing modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFmEp0r5T2eI"},"outputs":[],"source":["import pandas as pd\n","import os, time\n","from openai import OpenAI\n","from dotenv import load_dotenv\n","import json\n","import matplotlib.pyplot as plt\n","\n","print(\"Modules are imported.\")"]},{"cell_type":"markdown","metadata":{"id":"XfVAcV_XqDja"},"source":["Setting up the OpenAI API:\n","\n","* Prepare a .env file to store the OpenAI API key.\n","* Uploading the .env file to our colab environment\n","* Load the API key and setup the API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbXC4QM4qCBe"},"outputs":[],"source":["load_dotenv('apikey.env.txt')\n","\n","APIKEY = os.getenv('APIKEY')\n","ORGID = os.getenv('ORGID')"]},{"cell_type":"markdown","metadata":{"id":"rWxipGQIpxH8"},"source":["Creating OpenAI Client"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHj-RaA5p0WE"},"outputs":[],"source":["client = OpenAI(\n","    api_key=APIKEY,\n","    organization = ORGID\n",")\n","\n","client"]},{"cell_type":"markdown","metadata":{"id":"0r2XnfwnqTCK"},"source":["### Prepare the training data"]},{"cell_type":"markdown","metadata":{"id":"-_Alc-CyuHmE"},"source":["Loading the data `Customer Complaints.csv`\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jan2OKk5qW1J"},"outputs":[],"source":["training_data=pd.read_csv(\"Customer Complaints.csv)\"\n","training_data"]},{"cell_type":"markdown","metadata":{"id":"fWVCfuvRjdXa"},"source":["Defining a method that get's a row of the dataframe and convert it into the json format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tHnvRamq5NK"},"outputs":[],"source":["def save_as_json(row):\n","\n","  system_content = \"\"\"\n","      Given a customer complaint text, extract and return the following information in json (dict) format:\n","      - Topic: The product/department that the customer has a complaint about.\n","      - Problem: A two or three-word description of what exactly the problem is.\n","      - Customer_Dissatisfaction_Index: is a number between 0 and 100 showing\n","             how angry the customer is about the problem.\n","  \"\"\"\n","\n","  formatted_data = {\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": system_content},\n","            {\"role\": \"user\", \"content\": row.Complaints},\n","            {\"role\": \"assistant\", \"content\": row.Details}\n","        ]\n","      }\n","\n","  with open(\"training_data.json\", \"a\") as json_file:\n","        json.dump(formatted_data, json_file)\n","        json_file.write(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"K3haPgzI-ClF"},"source":["Using of this method to generate the `training_data.json`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LNOMxwSX8dE4"},"outputs":[],"source":["for index, row in training_data.iterrows():\n","save_as_json(row)"]},{"cell_type":"markdown","metadata":{"id":"Jo9HFdW0jput"},"source":["### Fine-tune GPT 3.5 based on the training data"]},{"cell_type":"markdown","metadata":{"id":"h4TMhzSNj4hH"},"source":["Importing the json file which was prepared as the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExJ2cRU5-XtH"},"outputs":[],"source":["data_file = client.files.create(\n","            file = open('training_data.json', 'rb'),\n","            purpose='fine-tune',\n",")\n","data_file"]},{"cell_type":"markdown","metadata":{"id":"TiBcO3I0kIU5"},"source":["Creating the Fine Tuning Job"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXJB348zkMSx"},"outputs":[],"source":["fine_tuning_job = client.fine_tuning.jobs.create(\n","    training_file = data_file.id,\n","    model = 'gpt-3.5-turbo',\n","    hyperparameters={\n","        \"n_epochs\": 1\n","    }\n",")\n","fine_tuning_job"]},{"cell_type":"markdown","metadata":{"id":"u7XWcO_7kzY6"},"source":["Retrieving the state of the fine-tune"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpbHjWu3AS4k"},"outputs":[],"source":["while True:\n","    time.sleep(2)\n","    retrieved_job = client.fine_tuning.jobs.retrieve(file_tuning_job.id)\n","    status = retrieved_job.status\n","    print(status)\n","\n","    if(status == \"succeeded\"):\n","        print(\"The job is done!\")\n","        break"]},{"cell_type":"markdown","metadata":{"id":"4XB-sFc3kO4A"},"source":["### Evaluate model"]},{"cell_type":"markdown","metadata":{"id":"p_3bNsW3k_eR"},"source":["Retrieving the event messages to check out the learning process of the fine-tuning job."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2bif68aIEGJ"},"outputs":[],"source":["events = list(client.fine_tuning.jobs.list_events(fine_tuning_job_id = retrieved_job.id, limit = 100).data)\n","\n","for e in events:\n","    print(e.message)"]},{"cell_type":"markdown","metadata":{"id":"Pe3jUJJjyeO1"},"source":["Extracting the training loss in each learning step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqhDoVBNzW_w"},"outputs":[],"source":["step = []\n","train_loss = []\n","\n","    for e in events:\n","        if(e.data):\n","            steps.append(e.data['step'])\n","            train_loss.append(e.data['train_loss'])\n","\n","    print(steps)\n","    print(train_loss)"]},{"cell_type":"markdown","metadata":{"id":"iiiJIUuq2W4D"},"source":["Using a line chart to visualize the train_loss in each step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMRvEd-F2bLO"},"outputs":[],"source":["plt.plot(steps, train_loss, marker = 'o', linestyle='-')"]},{"cell_type":"markdown","metadata":{"id":"8lGyZnvk25q9"},"source":["### Deploy our model"]},{"cell_type":"markdown","metadata":{"id":"EYljL-wH42ce"},"source":["Taking a look at `retrieved_job` again"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4ChDCWo3H85"},"outputs":[],"source":["myLLM = retrieved_job.fine_tuned_model\n","print(myLLM)"]},{"cell_type":"markdown","metadata":{"id":"nLLfuwC4-h9K"},"source":["Defining a method to extract information from a given user complaint using a specific LLM and return the results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3_99_Hf5CV1"},"outputs":[],"source":["def extract_details(user_complaint, model_name):\n","    \"\"\"\n","    This function extracts information from a given user complaint using a specific LLM (Large Language Model).\n","\n","    Parameters:\n","    user_complaint (str): The text of the user's complaint.\n","    model_name (str): The name of the specific LLM model to use for extraction.\n","    \"\"\"\n","\n","    system_content = \"\"\"\n","        Given a customer complaint text, extract and return the following information in JSON (dict) format:\n","        - Topic\n","        - Problem\n","        - Customer_Dissatisfaction_Index\n","    \"\"\"\n","\n","    # Generate a response using the specified model and the user's complaint\n","    response = client.chat.completions.create(\n","        model = model_name,\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_content},  # System content explaining the expected output\n","            {\"role\": \"user\", \"content\": user_complaint}  # User's complaint passed as content\n","        ]\n","    )\n","\n","    # Return the content of the generated response\n","    return response.choices[0].message.content\n"]},{"cell_type":"markdown","metadata":{"id":"zE_O2zAwplof"},"source":["Using the fine-tuned model to extract the details for the following user complaint:\n","\n","*TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vD1dEjnzWTuw"},"outputs":[],"source":["complaint = \"TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!\"\n","extract_details (complaint, myLLM)"]},{"cell_type":"markdown","metadata":{"id":"LJNgLZoS6-gw"},"source":["Testing the `GPT-4` model with the same user complaint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2XBuw0N47AC"},"outputs":[],"source":["extract_details(complaint, 'gpt-4')"]},{"cell_type":"markdown","metadata":{"id":"J3xZBAUitpVq"},"source":["Trying for the following complaint:\n","\n","*Line is down! It is really annoying!*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3O6HzK_ttZ7"},"outputs":[],"source":["complaint = \"Line is down! It is really annoying!\"\n","extract_details(complaint, myLLM)"]},{"cell_type":"markdown","metadata":{"id":"W4zeLRZfuNmS"},"source":["Comparing the results from GPT-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ubUkjXXuQ8X"},"outputs":[],"source":["extract_details(complaint,myLLM)"]},{"cell_type":"markdown","metadata":{"id":"YvqSymjWueXu"},"source":["The model, which is trained on the dataset, provides better answers compared to GPT-4. The model is fine-tuned based on the provided data and is familiar with the different edge cases and the context of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVQQfAAXy-v8"},"outputs":[],"source":["customer_complaint = \"I am very Angry! I want my money back!\"\n","extract_details(customer_complaint,myLLM)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1SDP1O_8CetQGTmzAHasiFFBZQ9oD2PUG","timestamp":1715708851722}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}